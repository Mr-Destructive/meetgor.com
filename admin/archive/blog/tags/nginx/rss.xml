<rss version="2.0">
  <channel>
    <title>Meet Gor - Tag: nginx</title>
    <link>meetgor.com</link>
    <description>Posts tagged with nginx</description>
    <language>en-us</language>
    <pubDate>Fri, 17 Oct 2025 16:57:38 UTC</pubDate>
    <item>
      <title>NGINX Survival Guide: Serving Web Applications</title>
      <link>meetgor.com/nginx-02-web-servers</link>
      <description>NGINX Fundamentals: Setting Up Simple HTTP Servers, Serving Custom Content, multiple upstream servers</description>
      <pubDate>Sun, 21 Jul 2024 00:00:00 UTC</pubDate>
      <content>&#xA;## Introduction&#xA;&#xA;In the second part of our NGINX Survival Guide, we dive into the practical aspects of using NGINX to serve web applications. This section will guide you through the essential tasks of setting up a basic HTTP server, configuring NGINX to serve content from custom directories, and using it as a reverse proxy to forward requests to backend servers.&#xA;&#xA;NGINX is a versatile web server that can be used to serve applications in a variety of ways, from simple web servers to complex proxy configurations. NGINX can be used to serve static HTML content, proxy requests to a backend server, or load balance traffic across multiple servers. In this guide, we&#39;ll explore the different ways to use NGINX to serve applications, including setting up a simple HTTP server, serving content from custom directories, and using it to load balance traffic across multiple upstream servers.&#xA;&#xA;## Simple HTTP Server&#xA;&#xA;NGINX serves as the default HTTP server on port 80 of your local machine if NGINX is properly installed and running on your system. If you head on to the localhost, you will see the default NGINX HTML page like the one below:&#xA;&#xA;![NGINX Default Page](https://meetgor-cdn.pages.dev/nginx-survival-guide/nginx-default-page.png)&#xA;&#xA;This is the default HTML page served by NGINX as per the configuration in the `/etc/nginx/nginx.conf` file. The default folder for NGINX to serve HTML content is located at `/usr/share/nginx/html/index.html` , If you change the contents of this file and restart NGINX, the http server will load the new HTML content.&#xA;&#xA;Let&#39;s first look, at how we can serve a simple http message within the configuration file in NGINX.&#xA;&#xA;## Serving simple text&#xA;&#xA;We will try to write our simple HTTP server from scratch, so it would be nice to empty the existing `/etc/nginx/nginx.conf` file or use other ports to serve the content rather than the default `127.0.0.1:80` port.&#xA;&#xA;```nginx&#xA;http {&#xA;    server {&#xA;        listen 8000;&#xA;        return 200 &#34;Hello, World!&#xA;&#34;;&#xA;    }&#xA;}&#xA;```&#xA;&#xA;The above config will serve the text `Hello, World!` when there is a request to the URL `127.0.0.1:8000` or `localhost:8000` You can change the port per your requirements and even add a `server_name` for your domain name.&#xA;&#xA;```bash&#xA;$ curl http://127.0.0.1:8000 &#xA;Hello, World!&#xA;&#xA;&#xA;$ curl -i http://127.0.0.1:8000&#xA;HTTP/1.1 200 OK&#xA;Server: nginx/1.18.0 (Ubuntu)&#xA;Date: Sat, 03 Feb 2024 11:41:16 GMT&#xA;Content-Type: application/octet-stream&#xA;Content-Length: 14&#xA;Connection: keep-alive&#xA;&#xA;Hello, World!&#xA;```&#xA;&#xA;As we can see the NGINX served the HTTP content when the request was made to port 8000 on the localhost.&#xA;&#xA;## Serving from a custom path/folder&#xA;&#xA;But things are not like these in the real world, we need to serve an entire directory of HTML pages. We need to add the `root` directive with the path to the folder where our HTML content resides. The path should have the `index.html` file as the starting point of the request.&#xA;&#xA;```nginx&#xA;http {&#xA;    server {&#xA;        listen 8000;&#xA;        root /srv/techstructive-blog;&#xA;        index index.html;&#xA;    }&#xA;}&#xA;```&#xA;&#xA;**NOTE: The path to the HTML content needs to be accessible and the Nginx process should have the read permission to serve the contents.**&#xA;&#xA;It is commonly recommended to store HTML/static content files in directories such as `/srv` or `/var/www`. These paths follow conventions for serving static files and web applications in Unix-type operating systems. While it&#39;s not a strict requirement, adhering to these conventions can improve the organization and maintainability of web content.&#xA;&#xA;## Serving from a web server&#xA;&#xA;If you already have a web server running in a port on your system, you could use Nginx as a gateway to the application instead of exposing your application to the internet.&#xA;&#xA;We could use the [proxy\_pass](https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_pass) directive in the location setting to specify which URL to pass the request to, the `listen` will forward the request to the proxy specified in the location directive.&#xA;&#xA;```nginx&#xA;http {&#xA;&#x9;server {&#xA;&#x9;&#x9;listen 80;&#xA;&#x9;&#x9;location / {&#xA;&#x9;&#x9;&#x9;proxy_pass http://localhost:8001;&#xA;&#x9;&#x9;}&#xA;&#x9;}&#xA;}&#xA;```&#xA;&#xA;In the above example, the NGINX listens to port 80 in the local system and sends the request to the localhost at port 8001. The `proxy_pass` is used to specify the URL to redirect the request to.&#xA;&#xA;* **listen 80:** Nginx listens for incoming requests on port 80, the standard HTTP port.&#xA;    &#xA;* **location /:** This directive matches all incoming requests, regardless of the path.&#xA;    &#xA;* **proxy\_pass**[**http://localhost:8001**](http://localhost:8001)**:** Requests are forwarded to the web application running on [localhost](http://localhost) at port 8001.&#xA;    &#xA;&#xA;This example configuration is a basic building block for setting up more complex proxy configurations with NGINX.&#xA;&#xA;## Serving from Multiple Upstream Servers&#xA;&#xA;NGINX can also serve content from multiple upstream servers, balancing the load between them. This is useful for high-traffic applications that require multiple backend servers to handle the load.&#xA;&#xA;What are upstream servers, you might ask, well in the context of NGINX, upstream servers refer to backend servers that handle the actual processing of requests. NGINX acts as a gateway, forwarding incoming requests to these upstream servers. This setup allows NGINX to manage the traffic efficiently and distribute it among multiple servers, which can be particularly beneficial for high-traffic applications. . For example, you might have your application running on [`localhost:8001`](http://localhost:8001) and [`localhost:8002`](http://localhost:8002).&#xA;&#xA;Hereâ€™s an example configuration:&#xA;&#xA;```nginx&#xA;http {&#xA;    upstream myapp {&#xA;        server backend1.example.com;&#xA;        server backend2.example.com;&#xA;        server backend3.example.com;&#xA;    }&#xA;&#xA;    server {&#xA;        listen 80;&#xA;&#xA;        location / {&#xA;            proxy_pass http://myapp;&#xA;        }&#xA;    }&#xA;}&#xA;```&#xA;&#xA;In this configuration:&#xA;&#xA;* The `upstream` block defines a named group of backend servers (`myapp`).&#xA;    &#xA;* The `server` block listens on port 80 and proxies requests to the upstream group defined earlier.&#xA;    &#xA;* `upstream myapp`: This directive creates a group of backend servers named `myapp`.&#xA;    &#xA;* [`server backend1.example.com`](http://backend1.example.com) : These directives list the backend servers that will handle the requests. These can be specified by hostname, IP address, or combination.&#xA;    &#xA;* `proxy_pass` [`http://myapp`](http://myapp): This directive tells NGINX to forward incoming requests to the `myapp` upstream group.&#xA;    &#xA;&#xA;### Why Use Upstream Servers?&#xA;&#xA;Using upstream servers has several advantages:&#xA;&#xA;* Scalability: By distributing requests across multiple servers, you can handle more traffic and scale your application horizontally.&#xA;    &#xA;* Fault Tolerance: If one of the backend servers goes down, NGINX can continue to serve requests using the remaining servers, ensuring high availability.&#xA;    &#xA;* Load Distribution: Upstream servers help in balancing the load, which can improve the performance and responsiveness of your web application.&#xA;    &#xA;&#xA;The below configuration sets up NGINX to act as a gateway that distributes incoming traffic to multiple upstream servers. It defines an upstream block with servers at [`localhost:8001`](http://localhost:8001) and [`localhost:8002`](http://localhost:8002), and forward requests to these servers.&#xA;&#xA;```nginx&#xA;http {&#xA;    upstream myapp {&#xA;        server localhost:8001;&#xA;        server localhost:8002;&#xA;    }&#xA;&#xA;    server {&#xA;        listen 80;&#xA;&#xA;        location / {&#xA;            proxy_pass http://myapp;&#xA;        }&#xA;    }&#xA;}&#xA;```&#xA;&#xA;The provided NGINX configuration sets up an upstream block named `myapp` with two backend servers running on [`localhost`](http://localhost) at ports 8001 and 8002. The server block listens on port 80 and uses a location block to match all incoming requests to the root URL (`/`). These requests are forwarded to the `myapp` upstream group via the `proxy_pass` directive, allowing NGINX to distribute the requests between the two backend servers, effectively balancing the load and enhancing the application&#39;s performance and reliability.&#xA;&#xA;## Conclusion&#xA;&#xA;From this part of ther series, we have learned how to set up a simple HTTP server to serve content from custom directories and using NGINX as a gateway to backend servers, which covered essential ways to utilize NGINX for serving web applications.&#xA;&#xA;That&#39;s it from this part of the series, we will look into detail how to use NGINX as a load balancer and reverse proxy, serving static files, and caching content in the next part of the series, where we&#39;ll dive deeper into advanced NGINX configurations.&#xA;Thank you for reading, hopefully you found this helpful. If you have any feedback, questions, or queries drop them below in the comments or reach me out directly on my social handles.&#xA;&#xA;Happy Coding :)&#xA;</content>
      <type>posts</type>
    </item>
    <item>
      <title>NGINX Basics and Setup</title>
      <link>meetgor.com/nginx-01-basics</link>
      <description>Exploring NGINX Fundamentals: A Guide for Backend Developers, from the Importance of Learning NGINX to Installation and Server Setup</description>
      <pubDate>Sun, 14 Jan 2024 00:00:00 UTC</pubDate>
      <content>&#xA;&#xA;## Introduction&#xA;&#xA;NGINX is a tool that can be used as a web server, reverse proxy, load balancer, streaming media files, application gateway, content caching, and so much more. It can be said to be a Swiss army knife for optimizing and securing your web application deployment.&#xA;&#xA;The series &#34;NGINX Survival Guide&#34; will start from the basics and cover the bare minimum required for a backend developer to get going with NGINX. I will use Docker widely throughout this course as it is a great combination with NGINX to server web applications. However, you can use NGINX without docker, and spawn multiple servers.&#xA;&#xA;The series will cover the terminologies of NGINX, configuring NGINX servers, load balancing multiple servers, using it as a reverse proxy, and as an API gateway, there will be tiny details and some tidbits of doing certain things in a certain constrained environment which will make the learning more valuable.&#xA;&#xA;## What is NGINX&#xA;&#xA;NGINX (pronounced &#34;engine-x&#34;) is not just a web server, it is a powerful and versatile open-source software that wears many hats in the internet world. At its core, it functions as a **lightning-fast web server**, its secret weapon lies in its **event-driven architecture**, where it handles requests asynchronously, allowing it to serve countless users simultaneously without breaking a sweat.&#xA;&#xA;&gt; NGINX is a popular choice for powering some of the **biggest websites and platforms in the world**, demonstrating its reliability and scalability.&#xA;&#xA;NGINX&#39;s **configurable nature** lets you tailor its behavior to your specific needs, whether managing traffic flow with load balancing, caching frequently accessed content for faster delivery, or even acting as a gateway for your APIs.&#xA;&#xA;This versatility makes NGINX a **powerful tool for building efficient, secure, and scalable web applications**, regardless of size or complexity. Hence the need to learn it as a developer and especially important for a backend developer.&#xA;&#xA;### Why NGINX is must learn for backend developers&#xA;&#xA;Nginx is a highly efficient and performant web server. Understanding its configuration and management allows a backend developer to optimize server performance, handle large volumes of traffic, and reduce latency.&#xA;&#xA;In microservices architectures, Nginx can serve as an API gateway, managing and routing requests between different services. Nginx provides caching mechanisms that enhance performance by serving cached content, reducing the load on backend servers.&#xA;&#xA;Having strong fundamentals in NGINX can indeed provide a competitive edge in the job market and make a backend developer more versatile in handling various aspects of backend web development.&#xA;&#xA;### Who is using NGINX?&#xA;&#xA;Big Tech Companies are using NGINX like DropBox, Netfilx, and Cloudflare, among others. Cloudflare used NGINX before but it was not enough for them, so they developed their web server/edge proxy suited to their needs called Pingora.&#xA;&#xA;* Dropbox - [Optimizing web servers for high throughput and low latency](https://dropbox.tech/infrastructure/optimizing-web-servers-for-high-throughput-and-low-latency)&#xA;&#xA;* Cloudflare - [How Cloudflare outgrown NGINX and made way to Pingora](https://blog.cloudflare.com/how-we-built-pingora-the-proxy-that-connects-cloudflare-to-the-internet/)&#xA;&#xA;* Netflix - [NGINX Netflix archives](https://www.nginx.com/blog/tag/netflix/)&#xA;&#xA;&#xA;## Installing NGINX&#xA;&#xA;### Linux&#xA;&#xA;There are comprehensive guides for your specific flavor/package manager/preferences in the [official documentation](https://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-open-source/) of NGINX.&#xA;&#xA;A couple of common types of installation medium instructions are as follows:&#xA;&#xA;```bash&#xA;# APT&#xA;sudo apt update&#xA;sudo apt install nginx&#xA;&#xA;# YUM&#xA;sudo yum install epel-release&#xA;sudo yum update&#xA;sudo yum install nginx&#xA;```&#xA;&#xA;Check the status of the NGINX service to ensure the installation was successful or not with the command:&#xA;&#xA;```bash&#xA;sudo systemctl status nginx&#xA;```&#xA;&#xA;If this doesn&#39;t have any errors or fatal messages, the nginx server is up and running on port 80 i.e. on `127.0.0.1` on the system.&#xA;&#xA;### MacOS&#xA;&#xA;The installation on MacOS for NGINX is pretty simple with homebrew. The following [article](https://dev.to/arjavdave/installing-nginx-on-mac-46ac) walks through the steps of the installation:&#xA;&#xA;```bash&#xA;brew update&#xA;brew install nginx&#xA;nginx&#xA;```&#xA;&#xA;If you do not want to install it from homebrew, this [gist](https://gist.github.com/beatfactor/a093e872824f770a2a0174345cacf171) can help install it from the source.&#xA;&#xA;### Windows&#xA;&#xA;For Windows installation, you can follow the [guide](https://nginx.org/en/docs/windows.html) from the official documentation.&#xA;&#xA;```bash&#xA;# INSTALL the https://nginx.org/en/download.html&#xA;# A Zip file with the name nginx-version.zip will be downlaoded&#xA;# COPY it to the desired location and use that path while unzipping&#xA;cd c:\&#xA;unzip nginx-1.25.3.zip&#xA;cd nginx-1.25.3&#xA;start nginx&#xA;```&#xA;&#xA;You can check the status of NGINX if the installation was successful or not with the command:&#xA;&#xA;```bash&#xA;tasklist /fi &#34;imagename eq nginx.exe&#34;&#xA;```&#xA;&#xA;This should be from the installation section.&#xA;&#xA;## Understanding the default config&#xA;&#xA;When you have completed the installation of nginx, you can see the default nginx configuration in the file path as `/etc/nginx/nginx.conf` in Linux/macOS or `C:&#xA;ginx&#xA;</content>
      <type>posts</type>
    </item>
  </channel>
</rss>