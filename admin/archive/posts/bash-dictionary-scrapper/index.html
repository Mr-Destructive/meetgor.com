<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <title>Scrapping the meaning of a word from dictionary.com using BASH script. | Meet Gor</title>
    <meta name="title" content="Scrapping the meaning of a word from dictionary.com using BASH script. | Meet Gor">
    <meta name="description" content="">
    <meta name="author" content="Meet Gor">
    <meta name="keywords" content="bash">
    <meta name="robots" content="index, follow">
    <link rel="canonical" href="meetgor.com/posts/bash-dictionary-scrapper">
    
    
    <meta property="og:type" content="article">
    <meta property="og:url" content="meetgor.com/posts/bash-dictionary-scrapper">
    <meta property="og:title" content="Scrapping the meaning of a word from dictionary.com using BASH script. | Meet Gor">
    <meta property="og:description" content="">
    <meta property="og:image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1627367329063/dabJLKcD-.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=compress">
    <meta property="og:site_name" content="Meet Gor">
    <meta property="article:published_time" content="2021-07-27">
    <meta property="article:modified_time" content="2021-07-27">
    <meta property="article:author" content="Meet Gor">
    
    <meta property="article:tag" content="bash">
    
    
    
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@meetgor711">
    <meta name="twitter:creator" content="@meetgor711">
    <meta name="twitter:url" content="meetgor.com/posts/bash-dictionary-scrapper">
    <meta name="twitter:title" content="Scrapping the meaning of a word from dictionary.com using BASH script. | Meet Gor">
    <meta name="twitter:description" content="">
    <meta name="twitter:image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1627367329063/dabJLKcD-.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=compress">
    
    
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "meetgor.com/posts\/bash-dictionary-scrapper"
        },
        "headline": "Scrapping the meaning of a word from dictionary.com using BASH script.",
        "description": "",
        "datePublished": "2021-07-27",
        "dateModified": "2021-07-27",
        "author": {
            "@type": "Person",
            "name": "Meet Gor"
        },
        "publisher": {
            "@type": "Organization",
            "name": "Meet Gor",
            "logo": {
                "@type": "ImageObject",
                "url": "meetgor.com/tbicon.png"
            }
        },
        "image": "https:\/\/cdn.hashnode.com\/res\/hashnode\/image\/upload\/v1627367329063\/dabJLKcD-.png?w=1600\u0026h=840\u0026fit=crop\u0026crop=entropy\u0026auto=compress",
        "keywords": "bash",
        "articleBody": "\u0026lt;h2 id=\u0026#34;introduction\u0026#34;\u0026gt;Introduction\u0026lt;\/h2\u0026gt;\n\u0026lt;p\u0026gt;Web Scraping is quite an interesting and powerful tool or skill to have in a Programmer\u0026#39;s toolkit.  It helps in analyzing data and getting some information in various formats. Web Scraping is a process in which a user fetches a website\u0026#39;s content using some pattern in those HTML tags and the desired content to be fetched or scraped.\u0026lt;\/p\u0026gt;\n\u0026lt;p\u0026gt;For this article, we aim to fetch the meaning of a word entered by the user from the dictionary.com website. We need to print just the meaning of the word from the HTML tags in it. We must have a good understanding of HTML and some basic Linux tools such as cURL, grep, sed, and others for doing all of these.\u0026lt;\/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;img src=\u0026#34;https:\/\/cdn.hashnode.com\/res\/hashnode\/image\/upload\/v1625737499658\/FGLusWSII.png\u0026#34; alt=\u0026#34;Inspecting the Target Website\u0026#34;\u0026gt;\u0026lt;\/p\u0026gt;\n\u0026lt;h2 id=\u0026#34;inspecting-the-target-website\u0026#34;\u0026gt;Inspecting the Target Website\u0026lt;\/h2\u0026gt;\n\u0026lt;p\u0026gt;To begin with, scrapping the website, first, it is absolutely important to inspect the website and view its source code. For that, we can make use of Inspect tool in our Browsers. Just Right-click on the website you are viewing or the website for scraping, a list of options appears in front of you. You have to select Inspect option( also Shift \u002b Ctrl \u002b I), this will open a side window with a plethora of options. You simply have to select Elements from the top of the menus. The code that you will see is the source code of the website. No, don\u0026#39;t think you can change the content of the website from here :)\u0026lt;\/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;img src=\u0026#34;https:\/\/cdn.hashnode.com\/res\/hashnode\/image\/upload\/v1625737510444\/KonUrEpcq-.png\u0026#34; alt=\u0026#34;image.png\u0026#34;\u0026gt;\nInspect Tool in the browser.\u0026lt;\/p\u0026gt;\n\u0026lt;p\u0026gt;Now we have to analyze the website with the content which we want to scrape. You can go on for clicking the \u0026lt;code\u0026gt;select the element in the page to inspect it\u0026lt;\/code\u0026gt; option or icon in the top left-hand side corner. This will allow you to inspect the particular element that you selected on the webpage. You can now see the element tag, id, class, and other attributes required to fetch the element\u0026#39;s content.\u0026lt;\/p\u0026gt;\n\u0026lt;h2 id=\u0026#34;selecting-the-particular-element-from-the-website-to-view-the-source-code\u0026#34;\u0026gt;Selecting the particular element from the website to view the source code.\u0026lt;\/h2\u0026gt;\n\u0026lt;h3 id=\u0026#34;accessing-the-website-from-the-command-lineterminal\u0026#34;\u0026gt;Accessing the website from the Command line\/terminal\u0026lt;\/h3\u0026gt;\n\u0026lt;p\u0026gt;Now the website structure is being understood we can actually move to scrap it. For that, we need to have the web site\u0026#39;s content on our local machine. First of all, we need to access the website from elsewhere not from the browser, because you cannot copy-paste content from there. So let\u0026#39;s use Command Line here. We have a popular tool known as \u0026lt;code\u0026gt;cURL\u0026lt;\/code\u0026gt;, which stands for client URL. The tool fetches the contents of the provided URL. It also has several parameters or arguments that can be used to modify its output. We can use the command\u0026lt;\/p\u0026gt;\n\u0026lt;div class=\u0026#34;code-block\u0026#34;\u0026gt;\u0026lt;div class=\u0026#34;code-header\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;language-name\u0026#34;\u0026gt;\u0026lt;\/span\u0026gt;\u0026lt;button class=\u0026#34;copy-button\u0026#34;\u0026gt;\u0026lt;svg xmlns=\u0026#34;http:\/\/www.w3.org\/2000\/svg\u0026#34; width=\u0026#34;24\u0026#34; height=\u0026#34;24\u0026#34; viewBox=\u0026#34;0 0 24 24\u0026#34; fill=\u0026#34;none\u0026#34; stroke=\u0026#34;currentColor\u0026#34; stroke-width=\u0026#34;2\u0026#34; stroke-linecap=\u0026#34;round\u0026#34; stroke-linejoin=\u0026#34;round\u0026#34; class=\u0026#34;feather feather-copy\u0026#34;\u0026gt;\u0026lt;rect x=\u0026#34;9\u0026#34; y=\u0026#34;9\u0026#34; width=\u0026#34;13\u0026#34; height=\u0026#34;13\u0026#34; rx=\u0026#34;2\u0026#34; ry=\u0026#34;2\u0026#34;\u0026gt;\u0026lt;\/rect\u0026gt;\u0026lt;path d=\u0026#34;M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1\u0026#34;\u0026gt;\u0026lt;\/path\u0026gt;\u0026lt;\/svg\u0026gt;\u0026lt;\/button\u0026gt;\u0026lt;\/div\u0026gt;\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;curl -o meaning.txt https:\/\/www.dictionary.com\/browse\/computer#\n\u0026lt;\/code\u0026gt;\u0026lt;\/pre\u0026gt;\u0026lt;\/div\u0026gt;\u0026lt;p\u0026gt;The above command fetches the HTML page for the word Computer, it could be any word you might be searching for.\u0026lt;\/p\u0026gt;\n\u0026lt;h3 id=\u0026#34;understanding-the-website-structure\u0026#34;\u0026gt;Understanding the Website Structure.\u0026lt;\/h3\u0026gt;\n\u0026lt;p\u0026gt;Here comes the time to explain the structure of dictionary.com. When you search a word on the website(dictionary.com), you are routed to \u0026lt;code\u0026gt;\/browse\u0026lt;\/code\u0026gt; which then fetches the word for you and defaults you to the \u0026lt;code\u0026gt;\/browse\/word#\u0026lt;\/code\u0026gt; (the word can be any word you searched). The curl command dumps the output in the \u0026lt;code\u0026gt;meaning.txt\u0026lt;\/code\u0026gt; or any specified file. If you see the contents of the file, it is the same as on the web.  So we are going to store the meaning of the searched word in the meaning.txt file, you can customize the name and command however you like.\u0026lt;\/p\u0026gt;\n\u0026lt;p\u0026gt;Voila! you successfully scraped a webpage. Now the next target is to filter the webpage content.\u0026lt;\/p\u0026gt;\n\u0026lt;h3 id=\u0026#34;filtering-content-from-website-local-file\u0026#34;\u0026gt;Filtering Content from Website local file\u0026lt;\/h3\u0026gt;\n\u0026lt;p\u0026gt;Now we have the content of the webpage on our local machine, we need to search or filter out the useful content and remove the unwanted tags and elements. For that, we can use commands such as \u0026lt;code\u0026gt;grep\u0026lt;\/code\u0026gt; and \u0026lt;code\u0026gt;sed\u0026lt;\/code\u0026gt;.\u0026lt;\/p\u0026gt;\n\u0026lt;h3 id=\u0026#34;finding-tags-to-extract-content\u0026#34;\u0026gt;Finding Tags to Extract content.\u0026lt;\/h3\u0026gt;\n\u0026lt;p\u0026gt;We need to find patterns and similarities in the tags that contain the text of the meaning of the specified word. From the analysis of the webpage, we see that the element \u0026lt;code\u0026gt;\u0026amp;lt;span class=\u0026amp;quot;one-click-content css-nnyc96 e1q3nk1v1\u0026amp;quot;\u0026amp;gt;\u0026lt;\/code\u0026gt; contains the actual meaning. We just need the basic meaning, we may not need examples and long lengthy definitions on our Terminal, So we will go with filtering out the span tag with a class called \u0026lt;code\u0026gt;one-click-content css-nnyc96 e1q3nk1v1\u0026lt;\/code\u0026gt;. To do that we can use the grep command, which can print the text or line matching the specified expression or text. Here we need the span element with the particular class name so we will use regular expressions to find it more effectively.\u0026lt;\/p\u0026gt;\n\u0026lt;div class=\u0026#34;code-block\u0026#34;\u0026gt;\u0026lt;div class=\u0026#34;code-header\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;language-name\u0026#34;\u0026gt;shell\u0026lt;\/span\u0026gt;\u0026lt;button class=\u0026#34;copy-button\u0026#34;\u0026gt;\u0026lt;svg xmlns=\u0026#34;http:\/\/www.w3.org\/2000\/svg\u0026#34; width=\u0026#34;24\u0026#34; height=\u0026#34;24\u0026#34; viewBox=\u0026#34;0 0 24 24\u0026#34; fill=\u0026#34;none\u0026#34; stroke=\u0026#34;currentColor\u0026#34; stroke-width=\u0026#34;2\u0026#34; stroke-linecap=\u0026#34;round\u0026#34; stroke-linejoin=\u0026#34;round\u0026#34; class=\u0026#34;feather feather-copy\u0026#34;\u0026gt;\u0026lt;rect x=\u0026#34;9\u0026#34; y=\u0026#34;9\u0026#34; width=\u0026#34;13\u0026#34; height=\u0026#34;13\u0026#34; rx=\u0026#34;2\u0026#34; ry=\u0026#34;2\u0026#34;\u0026gt;\u0026lt;\/rect\u0026gt;\u0026lt;path d=\u0026#34;M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1\u0026#34;\u0026gt;\u0026lt;\/path\u0026gt;\u0026lt;\/svg\u0026gt;\u0026lt;\/button\u0026gt;\u0026lt;\/div\u0026gt;\u0026lt;pre\u0026gt;\u0026lt;code class=\u0026#34;language-shell\u0026#34;\u0026gt;grep -oP \u0026#39;(?\u0026lt;=\u0026lt;span class=\u0026#34;one-click-content css-nnyc96 e1q3nk1v1\u0026#34;\u0026gt;).*?(?=\u0026lt;\/span\u0026gt;)\u0026#39; meaning.txt \u0026gt;temp.txt \n\u0026lt;\/code\u0026gt;\u0026lt;\/pre\u0026gt;\u0026lt;\/div\u0026gt;\u0026lt;h3 id=\u0026#34;using-grep-command-to-filter\u0026#34;\u0026gt;Using GREP command to filter.\u0026lt;\/h3\u0026gt;\n\u0026lt;p\u0026gt;The above command will search and return only lines that are contained in the span tags with that particular class name from the meaning.txt file which we appended to fill the webpage\u0026#39;s source code. The \u0026lt;code\u0026gt;-oP\u0026lt;\/code\u0026gt; are the arguments that return Only the matching cases and \u0026lt;code\u0026gt;-P\u0026lt;\/code\u0026gt; the coming expression is a Perl Regex. The command will return everything in between those tags. Finally, we are storing the result or output in \u0026lt;code\u0026gt;temp.txt\u0026lt;\/code\u0026gt;.\u0026lt;\/p\u0026gt;\n\u0026lt;p\u0026gt;Now, if you think we are done, then it\u0026#39;s wrong, the webpage can have internal or external links embedded inside of the elements as well, so we need to again filter out the HTML tags from the \u0026lt;code\u0026gt;temp.txt\u0026lt;\/code\u0026gt; file. For that, we will introduce another tool to filter text called \u0026lt;code\u0026gt;sed\u0026lt;\/code\u0026gt; or Stream editor. This tool allows us to filter the stream field and print or store the outcome. The following code will remove the HTML tags from the scrapped text.\u0026lt;\/p\u0026gt;\n\u0026lt;h3 id=\u0026#34;using-sed-command-to-remove-embedded\u0026#34;\u0026gt;Using SED command to remove embedded\u0026lt;\/h3\u0026gt;\n\u0026lt;div class=\u0026#34;code-block\u0026#34;\u0026gt;\u0026lt;div class=\u0026#34;code-header\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;language-name\u0026#34;\u0026gt;shell\u0026lt;\/span\u0026gt;\u0026lt;button class=\u0026#34;copy-button\u0026#34;\u0026gt;\u0026lt;svg xmlns=\u0026#34;http:\/\/www.w3.org\/2000\/svg\u0026#34; width=\u0026#34;24\u0026#34; height=\u0026#34;24\u0026#34; viewBox=\u0026#34;0 0 24 24\u0026#34; fill=\u0026#34;none\u0026#34; stroke=\u0026#34;currentColor\u0026#34; stroke-width=\u0026#34;2\u0026#34; stroke-linecap=\u0026#34;round\u0026#34; stroke-linejoin=\u0026#34;round\u0026#34; class=\u0026#34;feather feather-copy\u0026#34;\u0026gt;\u0026lt;rect x=\u0026#34;9\u0026#34; y=\u0026#34;9\u0026#34; width=\u0026#34;13\u0026#34; height=\u0026#34;13\u0026#34; rx=\u0026#34;2\u0026#34; ry=\u0026#34;2\u0026#34;\u0026gt;\u0026lt;\/rect\u0026gt;\u0026lt;path d=\u0026#34;M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1\u0026#34;\u0026gt;\u0026lt;\/path\u0026gt;\u0026lt;\/svg\u0026gt;\u0026lt;\/button\u0026gt;\u0026lt;\/div\u0026gt;\u0026lt;pre\u0026gt;\u0026lt;code class=\u0026#34;language-shell\u0026#34;\u0026gt; sed -i \u0026#39;s\/\u0026lt;[^\u0026gt;]*\u0026gt;\/\/g\u0026#39; temp.txt \u0026gt;meaning.txt\n\u0026lt;\/code\u0026gt;\u0026lt;\/pre\u0026gt;\u0026lt;\/div\u0026gt;\u0026lt;p\u0026gt;The above command filters the text and removes the HTML tags from the \u0026lt;code\u0026gt;temp.txt \u0026lt;\/code\u0026gt;file using regular expressions. The \u0026lt;code\u0026gt;-i\u0026lt;\/code\u0026gt; command allows us to store the output in a file \u0026lt;code\u0026gt;meaning.txt\u0026lt;\/code\u0026gt;.  We have used Regex to remove \u0026lt;code\u0026gt;\u0026amp;lt;\u0026amp;gt;\u0026lt;\/code\u0026gt; tags from the file and hence anything in between these is also removed and we get the only pure text but it may also contain special characters and symbols. To remove that we\u0026#39;ll again use \u0026lt;code\u0026gt;grep\u0026lt;\/code\u0026gt; and filter the fine meaning in our file.\u0026lt;\/p\u0026gt;\n\u0026lt;h3 id=\u0026#34;removing-special-characters-from-the-content-using-grep-commands\u0026#34;\u0026gt;Removing Special Characters from the Content using GREP commands.\u0026lt;\/h3\u0026gt;\n\u0026lt;div class=\u0026#34;code-block\u0026#34;\u0026gt;\u0026lt;div class=\u0026#34;code-header\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;language-name\u0026#34;\u0026gt;shell\u0026lt;\/span\u0026gt;\u0026lt;button class=\u0026#34;copy-button\u0026#34;\u0026gt;\u0026lt;svg xmlns=\u0026#34;http:\/\/www.w3.org\/2000\/svg\u0026#34; width=\u0026#34;24\u0026#34; height=\u0026#34;24\u0026#34; viewBox=\u0026#34;0 0 24 24\u0026#34; fill=\u0026#34;none\u0026#34; stroke=\u0026#34;currentColor\u0026#34; stroke-width=\u0026#34;2\u0026#34; stroke-linecap=\u0026#34;round\u0026#34; stroke-linejoin=\u0026#34;round\u0026#34; class=\u0026#34;feather feather-copy\u0026#34;\u0026gt;\u0026lt;rect x=\u0026#34;9\u0026#34; y=\u0026#34;9\u0026#34; width=\u0026#34;13\u0026#34; height=\u0026#34;13\u0026#34; rx=\u0026#34;2\u0026#34; ry=\u0026#34;2\u0026#34;\u0026gt;\u0026lt;\/rect\u0026gt;\u0026lt;path d=\u0026#34;M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1\u0026#34;\u0026gt;\u0026lt;\/path\u0026gt;\u0026lt;\/svg\u0026gt;\u0026lt;\/button\u0026gt;\u0026lt;\/div\u0026gt;\u0026lt;pre\u0026gt;\u0026lt;code class=\u0026#34;language-shell\u0026#34;\u0026gt; grep -v \u0026#39;^\\s*$\\|^\\s*\\#\u0026#39; temp.txt \u0026gt;meaning.txt\n\u0026lt;\/code\u0026gt;\u0026lt;\/pre\u0026gt;\u0026lt;\/div\u0026gt;\u0026lt;p\u0026gt;Now from the above command removes the special characters such as \u0026lt;code\u0026gt;$,#\u0026lt;\/code\u0026gt;, and others from the temp.txt file. We finally store everything filtered in the meaning.txt file. If you understood till here, the next concrete step will be super easy for you, as we will assemble everything here in a shell script.\u0026lt;\/p\u0026gt;\n\u0026lt;h2 id=\u0026#34;making-the-shell-script\u0026#34;\u0026gt;Making the Shell Script\u0026lt;\/h2\u0026gt;\n\u0026lt;div class=\u0026#34;code-block\u0026#34;\u0026gt;\u0026lt;div class=\u0026#34;code-header\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;language-name\u0026#34;\u0026gt;bash\u0026lt;\/span\u0026gt;\u0026lt;button class=\u0026#34;copy-button\u0026#34;\u0026gt;\u0026lt;svg xmlns=\u0026#34;http:\/\/www.w3.org\/2000\/svg\u0026#34; width=\u0026#34;24\u0026#34; height=\u0026#34;24\u0026#34; viewBox=\u0026#34;0 0 24 24\u0026#34; fill=\u0026#34;none\u0026#34; stroke=\u0026#34;currentColor\u0026#34; stroke-width=\u0026#34;2\u0026#34; stroke-linecap=\u0026#34;round\u0026#34; stroke-linejoin=\u0026#34;round\u0026#34; class=\u0026#34;feather feather-copy\u0026#34;\u0026gt;\u0026lt;rect x=\u0026#34;9\u0026#34; y=\u0026#34;9\u0026#34; width=\u0026#34;13\u0026#34; height=\u0026#34;13\u0026#34; rx=\u0026#34;2\u0026#34; ry=\u0026#34;2\u0026#34;\u0026gt;\u0026lt;\/rect\u0026gt;\u0026lt;path d=\u0026#34;M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1\u0026#34;\u0026gt;\u0026lt;\/path\u0026gt;\u0026lt;\/svg\u0026gt;\u0026lt;\/button\u0026gt;\u0026lt;\/div\u0026gt;\u0026lt;pre\u0026gt;\u0026lt;code class=\u0026#34;language-bash\u0026#34;\u0026gt;#!\/bin\/bash\n\nread -p \u0026#34;Enter the word to find meaning : \u0026#34; word\noutput=\u0026#34;meaning.txt\u0026#34;\nurl=\u0026#34;https:\/\/www.dictionary.com\/browse\/$word#\u0026#34;\n\ncurl -o $output $url \nclear\ngrep -oP \u0026#39;(?\u0026lt;=\u0026lt;span class=\u0026#34;one-click-content css-nnyc96 e1q3nk1v1\u0026#34;\u0026gt;).*?(?=\u0026lt;\/span\u0026gt;)\u0026#39; $output \u0026gt;temp.txt \n\nsed -i \u0026#39;s\/\u0026lt;[^\u0026gt;]*\u0026gt;\/\/g\u0026#39; temp.txt \u0026gt;$output\ngrep -v \u0026#39;^\\s*$\\|^\\s*\\#\u0026#39; temp.txt \u0026gt;$output\necho \u0026#34;$word\u0026#34;\nwhile read meaning \ndo\n\techo $meaning\ndone \u0026lt; $output\n\u0026lt;\/code\u0026gt;\u0026lt;\/pre\u0026gt;\u0026lt;\/div\u0026gt;\u0026lt;p\u0026gt;We can clearly see most of the commands are the same, but some have been modified to avoid repetition and automation. Firstly, I have taken user input of word from the user and stored it in with an appropriate variable name.  Next, I have created another variable to store the file name in which we are going to store the meaning of the word, Also a variable for the URL of the website we are searching for. We have used a variable to access the required URL. Then we invoke \u0026lt;code\u0026gt;cURL\u0026lt;\/code\u0026gt; to the file which we want to store using the variable we created and the URL variable So creating variables makes our script quite easy to manage and also it improves the readability of the script.\u0026lt;\/p\u0026gt;\n\u0026lt;h2 id=\u0026#34;updating-curl-command\u0026#34;\u0026gt;Updating cURL command\u0026lt;\/h2\u0026gt;\n\u0026lt;p\u0026gt;We can also update the curl command by adding \u0026lt;code\u0026gt;\u0026amp;quot;\u0026amp;amp;\u0026amp;gt; \/dev\/null\u0026amp;quot;\u0026lt;\/code\u0026gt; this will dump the curl output of network analysis. So we will only get the output of the meaning.txt file.  It is optional to add the following into your code as it depends on the operating system so we can optionally use clear command to wipe out the curl output.\u0026lt;\/p\u0026gt;\n\u0026lt;h2 id=\u0026#34;printing-the-output-file-line-by-line\u0026#34;\u0026gt;Printing the output file line by line.\u0026lt;\/h2\u0026gt;\n\u0026lt;p\u0026gt;To print the meaning in the output file, we need to print each line separately as the meanings are distinct. Therefore, we will use a while loop with the output file and echo the line variable we have used as the loop iterator.\u0026lt;\/p\u0026gt;\n\u0026lt;h2 id=\u0026#34;script-screenshots\u0026#34;\u0026gt;Script Screenshots:\u0026lt;\/h2\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;img src=\u0026#34;https:\/\/cdn.hashnode.com\/res\/hashnode\/image\/upload\/v1627366344193\/We_heehuL.gif\u0026#34; alt=\u0026#34;dict.gif\u0026#34;\u0026gt;\u0026lt;\/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;img src=\u0026#34;https:\/\/cdn.hashnode.com\/res\/hashnode\/image\/upload\/v1627365131696\/YH8Vaqoh_.png\u0026#34; alt=\u0026#34;image.png\u0026#34;\u0026gt;\u0026lt;\/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;img src=\u0026#34;https:\/\/cdn.hashnode.com\/res\/hashnode\/image\/upload\/v1627365274090\/D9IETfRAh.png\u0026#34; alt=\u0026#34;image.png\u0026#34;\u0026gt;\u0026lt;\/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;img src=\u0026#34;https:\/\/cdn.hashnode.com\/res\/hashnode\/image\/upload\/v1627365304653\/A9AXuHDH8.png\u0026#34; alt=\u0026#34;image.png\u0026#34;\u0026gt;\u0026lt;\/p\u0026gt;\n\u0026lt;h2 id=\u0026#34;output-conclusion\u0026#34;\u0026gt;Output Conclusion\u0026lt;\/h2\u0026gt;\n\u0026lt;p\u0026gt;From the above output, we have scrapped the meaning of the word \u0026lt;code\u0026gt;Mathematics\u0026lt;\/code\u0026gt;, \u0026lt;code\u0026gt;code\u0026lt;\/code\u0026gt;, and \u0026lt;code\u0026gt;python\u0026lt;\/code\u0026gt;.  It works only for the words which are on the dictionary.com website. We have successfully made a scrapper that scraps the meaning of the input word from the dictionary.com website,\u0026lt;\/p\u0026gt;\n\u0026lt;h2 id=\u0026#34;appropriate-use-of-web-scrapping\u0026#34;\u0026gt;Appropriate use of Web-Scrapping.\u0026lt;\/h2\u0026gt;\n\u0026lt;p\u0026gt;We must be careful and not scrape any website without reading its privacy policy. If they allow scraping from their website, then only you should scrape the content and not use it for any monetization of the content. This was just used for demonstrating some idea about web scrapping using BASH and just meant for teaching purposes.\u0026lt;\/p\u0026gt;\n\u0026lt;p\u0026gt;Therefore, it is quite easy to scrape the website\u0026#39;s content especially if you find any patterns in the code structure. We were able to make a script that can print the meaning of the input word from the base of the website dictionary.com.\u0026lt;\/p\u0026gt;\n\u0026lt;p\u0026gt;We can see how Bash can be powerful in terms of web scrapping. I hope you found this interesting and inspiring. Thank you for reading. Happy Coding :)\u0026lt;\/p\u0026gt;\n"
    }
    </script>
    
    
    <link rel="stylesheet" href="/style.css">
    <link rel="stylesheet" href="/code-block.css">
    
    <link rel="icon" href="/tbicon.png" type="image/png">
    <link rel="apple-touch-icon" href="/tbicon.png">
    
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <link id="syntax-theme" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/go.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/sql.js/1.13.0/sql-wasm.js"></script>
    <link rel="stylesheet" href="/sql-playground.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.15/codemirror.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.15/theme/monokai.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.15/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.15/mode/sql/sql.min.js"></script>
    <script src="/sql-playground.js"></script>
    
    <script src="https://unpkg.com/htmx.org@1.9.10"></script>
    <script>
    document.addEventListener("DOMContentLoaded", () => {
        const body = document.body;
        const stylesheet = document.getElementById("syntax-theme");
        const themeToggle = document.getElementById('theme-toggle');

        function setSyntaxTheme(theme) {
            if (theme === "secondary") {
                stylesheet.href = "https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css";
            } else {
                stylesheet.href = "https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css";
            }
        }

        
        document.querySelectorAll("pre code").forEach((block) => {
            hljs.highlightElement(block);
        });

        
        const currentTheme = localStorage.getItem("theme") || "default";
        if (currentTheme === "secondary") {
            body.classList.add("secondary-theme");
            if (themeToggle) themeToggle.checked = true;
        }
        setSyntaxTheme(currentTheme);

        
        if (themeToggle) {
            themeToggle.addEventListener('change', () => {
                const newTheme = themeToggle.checked ? 'secondary' : 'default';
                if (themeToggle.checked) {
                    body.classList.add('secondary-theme');
                } else {
                    body.classList.remove('secondary-theme');
                }
                localStorage.setItem('theme', newTheme);
                setSyntaxTheme(newTheme);
            });
        }
        
        
        const editBtn = document.getElementById('editor-edit');
        if (editBtn) {
            editBtn.addEventListener('click', async function () {
                const slug = "posts\/bash-dictionary-scrapper";
                const type = "posts";
                console.log("Editing post:", slug, type);
                const url = "https:\/\/devmeetgor.netlify.app/.netlify/functions/api?slug=" + slug + "&method=edit&type=" + type;
                
                try {
                    const res = await fetch(url);
                    if (!res.ok) throw new Error("Failed to fetch edit content");
                    const html = await res.text();
                    document.querySelector('.post-content').innerHTML = html;
                } catch (err) {
                    console.error(err);
                    alert("Error loading editor content");
                }
            });
        }
    });
    </script>
    
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-EET2ZX4QY1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-EET2ZX4QY1');
    </script>
</head>
<body>
    <header class="header">
  <a class="site-title" href="/" aria-label="Meet Gor - Home">Meet Gor</a>
  <nav>
    <ul>
      <li><a href="/" aria-label="Home">Home</a></li>
      <li><a href="/posts" aria-label="Posts">Posts</a></li>
      <li><a href="/about" aria-label="About">About</a></li>
      <li><a href="/contact" aria-label="Contact">Contact</a></li>
    </ul>
  </nav>
  <div class="theme-switch">
    <input type="checkbox" id="theme-toggle" aria-label="Toggle Theme">
    <label for="theme-toggle"></label>
  </div>
  
    <button id="editor" onclick="location.href='/editor'" aria-label="Editor">
      Editor
    </button>
  
</header>
    
    <main class="container">
        <article class="blog-post">
            <h1>Scrapping the meaning of a word from dictionary.com using BASH script.</h1>
            
            <div class="post-meta">
                Published on 📅 <time datetime="2021-07-27">2021-07-27</time>
            </div>
            
            <div class="post-meta">
                Type: <a href="/posts">posts</a>
            </div>
            
            <div class="post-meta tags">
                <span class="post-series-label">🏷️ Tags:</span>
                
                <a href="/tags/bash">#bash</a>
                
            </div>
            
            
            
            
            <div class="post-meta admin-controls">
                <button id="editor-edit">Edit</button>
                <button id="editor-delete" 
                        onclick="location.href='/editor/?slug=posts\/bash-dictionary-scrapper&method=delete'">
                    Delete
                </button>
            </div>
            
            
            <hr>
            
            <div class="post-content">
                <h2 id="introduction">Introduction</h2>
<p>Web Scraping is quite an interesting and powerful tool or skill to have in a Programmer's toolkit.  It helps in analyzing data and getting some information in various formats. Web Scraping is a process in which a user fetches a website's content using some pattern in those HTML tags and the desired content to be fetched or scraped.</p>
<p>For this article, we aim to fetch the meaning of a word entered by the user from the dictionary.com website. We need to print just the meaning of the word from the HTML tags in it. We must have a good understanding of HTML and some basic Linux tools such as cURL, grep, sed, and others for doing all of these.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1625737499658/FGLusWSII.png" alt="Inspecting the Target Website"></p>
<h2 id="inspecting-the-target-website">Inspecting the Target Website</h2>
<p>To begin with, scrapping the website, first, it is absolutely important to inspect the website and view its source code. For that, we can make use of Inspect tool in our Browsers. Just Right-click on the website you are viewing or the website for scraping, a list of options appears in front of you. You have to select Inspect option( also Shift + Ctrl + I), this will open a side window with a plethora of options. You simply have to select Elements from the top of the menus. The code that you will see is the source code of the website. No, don't think you can change the content of the website from here :)</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1625737510444/KonUrEpcq-.png" alt="image.png">
Inspect Tool in the browser.</p>
<p>Now we have to analyze the website with the content which we want to scrape. You can go on for clicking the <code>select the element in the page to inspect it</code> option or icon in the top left-hand side corner. This will allow you to inspect the particular element that you selected on the webpage. You can now see the element tag, id, class, and other attributes required to fetch the element's content.</p>
<h2 id="selecting-the-particular-element-from-the-website-to-view-the-source-code">Selecting the particular element from the website to view the source code.</h2>
<h3 id="accessing-the-website-from-the-command-lineterminal">Accessing the website from the Command line/terminal</h3>
<p>Now the website structure is being understood we can actually move to scrap it. For that, we need to have the web site's content on our local machine. First of all, we need to access the website from elsewhere not from the browser, because you cannot copy-paste content from there. So let's use Command Line here. We have a popular tool known as <code>cURL</code>, which stands for client URL. The tool fetches the contents of the provided URL. It also has several parameters or arguments that can be used to modify its output. We can use the command</p>
<div class="code-block"><div class="code-header"><span class="language-name"></span><button class="copy-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-copy"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></button></div><pre><code>curl -o meaning.txt https://www.dictionary.com/browse/computer#
</code></pre></div><p>The above command fetches the HTML page for the word Computer, it could be any word you might be searching for.</p>
<h3 id="understanding-the-website-structure">Understanding the Website Structure.</h3>
<p>Here comes the time to explain the structure of dictionary.com. When you search a word on the website(dictionary.com), you are routed to <code>/browse</code> which then fetches the word for you and defaults you to the <code>/browse/word#</code> (the word can be any word you searched). The curl command dumps the output in the <code>meaning.txt</code> or any specified file. If you see the contents of the file, it is the same as on the web.  So we are going to store the meaning of the searched word in the meaning.txt file, you can customize the name and command however you like.</p>
<p>Voila! you successfully scraped a webpage. Now the next target is to filter the webpage content.</p>
<h3 id="filtering-content-from-website-local-file">Filtering Content from Website local file</h3>
<p>Now we have the content of the webpage on our local machine, we need to search or filter out the useful content and remove the unwanted tags and elements. For that, we can use commands such as <code>grep</code> and <code>sed</code>.</p>
<h3 id="finding-tags-to-extract-content">Finding Tags to Extract content.</h3>
<p>We need to find patterns and similarities in the tags that contain the text of the meaning of the specified word. From the analysis of the webpage, we see that the element <code>&lt;span class=&quot;one-click-content css-nnyc96 e1q3nk1v1&quot;&gt;</code> contains the actual meaning. We just need the basic meaning, we may not need examples and long lengthy definitions on our Terminal, So we will go with filtering out the span tag with a class called <code>one-click-content css-nnyc96 e1q3nk1v1</code>. To do that we can use the grep command, which can print the text or line matching the specified expression or text. Here we need the span element with the particular class name so we will use regular expressions to find it more effectively.</p>
<div class="code-block"><div class="code-header"><span class="language-name">shell</span><button class="copy-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-copy"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></button></div><pre><code class="language-shell">grep -oP '(?<=<span class="one-click-content css-nnyc96 e1q3nk1v1">).*?(?=</span>)' meaning.txt >temp.txt 
</code></pre></div><h3 id="using-grep-command-to-filter">Using GREP command to filter.</h3>
<p>The above command will search and return only lines that are contained in the span tags with that particular class name from the meaning.txt file which we appended to fill the webpage's source code. The <code>-oP</code> are the arguments that return Only the matching cases and <code>-P</code> the coming expression is a Perl Regex. The command will return everything in between those tags. Finally, we are storing the result or output in <code>temp.txt</code>.</p>
<p>Now, if you think we are done, then it's wrong, the webpage can have internal or external links embedded inside of the elements as well, so we need to again filter out the HTML tags from the <code>temp.txt</code> file. For that, we will introduce another tool to filter text called <code>sed</code> or Stream editor. This tool allows us to filter the stream field and print or store the outcome. The following code will remove the HTML tags from the scrapped text.</p>
<h3 id="using-sed-command-to-remove-embedded">Using SED command to remove embedded</h3>
<div class="code-block"><div class="code-header"><span class="language-name">shell</span><button class="copy-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-copy"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></button></div><pre><code class="language-shell"> sed -i 's/<[^>]*>//g' temp.txt >meaning.txt
</code></pre></div><p>The above command filters the text and removes the HTML tags from the <code>temp.txt </code>file using regular expressions. The <code>-i</code> command allows us to store the output in a file <code>meaning.txt</code>.  We have used Regex to remove <code>&lt;&gt;</code> tags from the file and hence anything in between these is also removed and we get the only pure text but it may also contain special characters and symbols. To remove that we'll again use <code>grep</code> and filter the fine meaning in our file.</p>
<h3 id="removing-special-characters-from-the-content-using-grep-commands">Removing Special Characters from the Content using GREP commands.</h3>
<div class="code-block"><div class="code-header"><span class="language-name">shell</span><button class="copy-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-copy"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></button></div><pre><code class="language-shell"> grep -v '^\s*$\|^\s*\#' temp.txt >meaning.txt
</code></pre></div><p>Now from the above command removes the special characters such as <code>$,#</code>, and others from the temp.txt file. We finally store everything filtered in the meaning.txt file. If you understood till here, the next concrete step will be super easy for you, as we will assemble everything here in a shell script.</p>
<h2 id="making-the-shell-script">Making the Shell Script</h2>
<div class="code-block"><div class="code-header"><span class="language-name">bash</span><button class="copy-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-copy"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></button></div><pre><code class="language-bash">#!/bin/bash

read -p "Enter the word to find meaning : " word
output="meaning.txt"
url="https://www.dictionary.com/browse/$word#"

curl -o $output $url 
clear
grep -oP '(?<=<span class="one-click-content css-nnyc96 e1q3nk1v1">).*?(?=</span>)' $output >temp.txt 

sed -i 's/<[^>]*>//g' temp.txt >$output
grep -v '^\s*$\|^\s*\#' temp.txt >$output
echo "$word"
while read meaning 
do
	echo $meaning
done < $output
</code></pre></div><p>We can clearly see most of the commands are the same, but some have been modified to avoid repetition and automation. Firstly, I have taken user input of word from the user and stored it in with an appropriate variable name.  Next, I have created another variable to store the file name in which we are going to store the meaning of the word, Also a variable for the URL of the website we are searching for. We have used a variable to access the required URL. Then we invoke <code>cURL</code> to the file which we want to store using the variable we created and the URL variable So creating variables makes our script quite easy to manage and also it improves the readability of the script.</p>
<h2 id="updating-curl-command">Updating cURL command</h2>
<p>We can also update the curl command by adding <code>&quot;&amp;&gt; /dev/null&quot;</code> this will dump the curl output of network analysis. So we will only get the output of the meaning.txt file.  It is optional to add the following into your code as it depends on the operating system so we can optionally use clear command to wipe out the curl output.</p>
<h2 id="printing-the-output-file-line-by-line">Printing the output file line by line.</h2>
<p>To print the meaning in the output file, we need to print each line separately as the meanings are distinct. Therefore, we will use a while loop with the output file and echo the line variable we have used as the loop iterator.</p>
<h2 id="script-screenshots">Script Screenshots:</h2>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1627366344193/We_heehuL.gif" alt="dict.gif"></p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1627365131696/YH8Vaqoh_.png" alt="image.png"></p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1627365274090/D9IETfRAh.png" alt="image.png"></p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1627365304653/A9AXuHDH8.png" alt="image.png"></p>
<h2 id="output-conclusion">Output Conclusion</h2>
<p>From the above output, we have scrapped the meaning of the word <code>Mathematics</code>, <code>code</code>, and <code>python</code>.  It works only for the words which are on the dictionary.com website. We have successfully made a scrapper that scraps the meaning of the input word from the dictionary.com website,</p>
<h2 id="appropriate-use-of-web-scrapping">Appropriate use of Web-Scrapping.</h2>
<p>We must be careful and not scrape any website without reading its privacy policy. If they allow scraping from their website, then only you should scrape the content and not use it for any monetization of the content. This was just used for demonstrating some idea about web scrapping using BASH and just meant for teaching purposes.</p>
<p>Therefore, it is quite easy to scrape the website's content especially if you find any patterns in the code structure. We were able to make a script that can print the meaning of the input word from the base of the website dictionary.com.</p>
<p>We can see how Bash can be powerful in terms of web scrapping. I hope you found this interesting and inspiring. Thank you for reading. Happy Coding :)</p>

            </div>
        </article>
    </main>
    
    <div id="comments">
        <script src="https://giscus.app/client.js"
            data-repo="Mr-Destructive/meetgor.com"
            data-repo-id="R_kgDOHZ6V_g"
            data-category="Q&A"
            data-category-id="DIC_kwDOHZ6V_s4CRfn4"
            data-mapping="pathname"
            data-strict="0"
            data-reactions-enabled="1"
            data-emit-metadata="0"
            data-input-position="bottom"
            data-theme="dark_high_contrast"
            data-lang="en"
            crossorigin="anonymous"
            async>
        </script>
    </div>
    
    <footer class="site-footer" role="contentinfo">
  <div class="footer-content">
    <p>&copy; Meet Gor. All rights reserved.</p>
    <div class="social-links">
      <a href="/contact" aria-label="Connect with me">Connect with me</a>
    </div>
  </div>
</footer>
    
</body>
</html>
